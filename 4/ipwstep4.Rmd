---
title: "IPW Simulation Results 4"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r results='asis', echo=FALSE, include=FALSE}

library(knitr)
library(xlsx)
library(kableExtra)

library(jomo)
library(geepack)
library(lme4)
library(jomo)
library(CRTgeeDR)

expit=function(x){b=exp(x)/(1+exp(x));return(b)}
myTryCatch <- function(expr) {
  warn <- err <- NULL
  value <- withCallingHandlers(
    tryCatch(expr, error=function(e) {
      err <<- e
      NULL
    }), warning=function(w) {
      warn <<- w
      invokeRestart("muffleWarning")
    })
  list(value=value, warning=warn, error=err)
}
one_group3=function(mis,s,i,k,mm,seed=123){
  set.seed(seed)
  if(s==1){b0=1;b1=1.36;b2=1;psi=-1.34}
  if(s==3){b0=1;b1=1.36;b2=0.588;psi=-1.34}
  ## parameters
  sigma_b=sqrt(0.2)
  mu_x=0
  sigma_alpha=sqrt(0.18)
  sigma_u=sqrt(3.37)
  
  phi=1
  x=matrix(0,k,mm+5*(mm/25))
  y=matrix(0,k,mm+5*(mm/25))
  pi=matrix(0,k,mm+5*(mm/25))
  cluster=matrix(0,k,mm+5*(mm/25))
  r=matrix(0,k,mm+5*(mm/25))
  mis_clu=matrix(0,k,mm+5*(mm/25))
  groups=matrix(i,k,mm+5*(mm/25))
  for(kk in 1:k){
    delta=rnorm(1,0,sigma_b)
    alpha=rnorm(1,mu_x,sigma_alpha)
    m=round(runif(1,mm-5*(mm/25),mm+5*(mm/25)))
    # print(m)
    cluster[kk,]=kk
    sigma_icc=0.4
    clu=rnorm(1,0,sqrt(sigma_icc))
    # print(m)
    mis_clu[kk,]=clu
    for(j in 1:m){
      u=rnorm(1,0,sigma_u)
      x[kk,j]=u+alpha
      pi[kk,j]=expit(b0+b1*i+b2*x[kk,j]+delta)
      y[kk,j]=rbinom(1,1,pi[kk,j])
    }
  }
  #r=expit(psi+phi*x)
  if(mis==1){r=expit(psi+phi*x)}
  if(mis==2){r=expit(psi+phi*x+groups)}
  if(mis==3){r=expit(psi+phi*x+groups+x*groups)}
  if(mis==4){r=expit(psi+phi*x+mis_clu)}
  if(mis==5){r=expit(psi+phi*x+groups+mis_clu)}
  if(mis==6){r=expit(psi+phi*x+groups+x*groups+mis_clu)}
  return(list(x=x,y=y,pi=pi,r=r,cluster=cluster))
}
data_gene3=function(k,m,s,mis,seed=123){
  set.seed(seed)
  # step1:
  a1=one_group3(i=1,k=k,m=m,seed=seed,mis=mis,s=s)
  a0=one_group3(i=0,k=k,m=m,seed=seed,mis=mis,s=s)
  # step2
  b1=data.frame(x=c(a1$x),y=c(a1$y),r=c(a1$r),cluster=c(a1$cluster))
  R=c()
  for(i in 1:dim(b1)[1]){
    R[i]=rbinom(1,1,b1$r[i])
  }
  b1$R=R
  b1$arm=1
  b1$cluster=b1$cluster+k
  b0=data.frame(x=c(a0$x),y=c(a0$y),r=c(a0$r),cluster=c(a0$cluster))
  R=c()
  for(i in 1:dim(b0)[1]){
    R[i]=rbinom(1,1,b0$r[i])
  }
  b0$R=R
  b0$arm=0
  # step3:
  data=rbind(b0,b1)
  data0=data[data$x!=0,]
  return(data0)
}
conv=function(means,sds,true){
  n=0
  temp=data.frame(means=means,sds=sds)
  temp=na.omit(temp)
  means=temp$means
  sds=temp$sds
  for(i in 1:length(means)){
    if(means[i]-1.96*sds[i]<true & means[i]+1.96*sds[i]> true){n=n+1}
  }
  return(n)
}
miss_per=function(a){
  b=sum(a$R)/dim(a)[1]
  return(b)
}

```


## Recall:

### 1. Data Generation Function: 
$$\pi_{ijl}=exp(\beta_0+\beta_1 i +f_i (x_{ijl})+\delta_{ij}) $$ 
With values:
$$\pi_{ijl}=exp(1+1.36 i +x_{ijl}+\delta_{ij}) , \text{ }  \delta_{ij} \sim N(0,0.2) $$

* *ijl* means the *ith* intervention group, the *jth* cluster, the *lth* individual.

* *i*=0 control group while *i*=1 intervention group.

*  $\beta_0$ is a constant, $\beta_1$ is the true intervention effect. $f_i (x_{ijl})$ is a function of baseline coveariate X in the *ith* intervention group. 
We set $f_0 (x_{ijl})=f_1 (x_{ijl})=\beta_2 x_{ijl}$, $\beta_0=1, \beta_1=1.36, \beta_2=1$, which consistent to Hossain's paper.

*  $X_{ijl}$ is generated by using the methods:
$$ X_{ijl}=\alpha_{ij}+u_{ijl} $$
$$ \alpha_{ij} \sim N(0,0.18), u_{ijl} \sim N(0,3.37) $$
where $\alpha_{ij}$ is the (ij)th cluster effect on X and $u_{ijl}$ is the individual-level error on X. Therefore, the variance of x is $0.18+3.37=3.55$, the ICC is $\rho=0.18/3.55=0.05$

* $\delta_{ij}$ ~ $N(0,\sigma^2_b)$. We set $\sigma^2_b=0.2$

* $Y_{ijl}$ is generated as Bernoulli random varaible with parameter $\pi_{ijl}$

We tried k=25 and k=50 clusters in each intervention arm, respectively. And we also considered cluster size with mean m=25 and m=50, where the cluster size was chosen from uniform distributions: UNI(20,30) and UNI(45,55). 

Since we are also considering to mimic the HALI data, the simulation should have the similar CV of cluster size as HALI data, which is about 0.1. 
And the UNI(20,30) is appropriate for mimicking the HALI cluster size with a similar CV. The other cluster size distribution is revised as UNI(40,60) so that the CV is around 0.1. That is:

* With mean=25, m $\sim$ UNI(20,30)

* With mean=50, m $\sim$ UNI(40,60) 

### 2. Missingness generation:
We assume the missing mechanism is covariate dependent missingness (CDM). 

The missingness is generated by the logistic regression model (the original method in Hossain's paper):
$$ logit(R_{ijl}=0|Y_{ij},X_{ij})=\psi_i + \phi_i X_{ijl}$$
With values:
$$ logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}$$

The following table shows the parameters used in Hossain's paper. And we used the same parameters as Hossain's. 


<center>Parameter Table in Hossain's Paper</center >
|Parameter | S1 | S2 |
|:------------- | :-------------|
|$\beta_0$ | 0 | 0|
|$\beta_1$ | 1.36 |1.36|
|$\beta_2$ | 1| 0.588 |
|$\alpha_{ij}$| $N(\mu_x,\sigma^2_{\alpha})$|
|$u_{ijl}$  |  $N(0,\sigma^2_{u})$|
|$\psi_0=\psi_1$  | -1.34|
|$\phi_0=\phi_1$| 1|
|$\mu_x$ | 0|
|$\sigma^2_{\alpha}$|0.18|
|$\sigma^2_u$|3.37|
|$\delta_{ij}$|$N(0,\sigma^2_b)$|
|$\sigma^2_b$|0.2|

This time we consider two scenarios in Hossain's paper: scenario 1 and scenario 3. 

In scenario 1, covariate of X in each intervention group is the same while in scenario 3 is different. However, the missing generation methods are the same in these two scenarios since the generation is not associated with intervention arm and the parameters are the same. 

We then tried to consider more scenarios in missingness generation. 

### 3. More missingness generation models based on previous results 

#### Missingness Model 1. x

This scenario only contains covariate X in missingness generation model. The model is the same in the different intervention arm and cluster effects are not considered. 

$$logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}$$

#### Missingness Model 2. x+arm

A convariate representing intervention arm is added. In Hossain's paper, S2 and S4 have different missing generation models since:

Control arm: $logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}$

Intervention arm: $logit(R_{ijl}=0|Y_{ij},X_{ij})=0.65 + X_{ijl}$

which means the coefficient for arm covariate is 1.99. However, I did not choose this coefficient since it increases the missing percentage from 30 $\%$ to 60 $\%$, which may make these scenarios uncomparable. So I just choose 1 as the coefficient and the model is specified as: 

$$logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}+i$$

#### Missingness Model 3. x+arm+x:arm

In Hossain's paper, the $\phi_0=\phi_1=1$, which does not consider the interactions. Here, in missing model 3, we add an interaction of covariate X and intervention arm. And the coefficient of the interaction part is chosen as 1.  

$$logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}+i+X_{ijl}*i$$

#### Missingness Model 4. x+$\theta_{ij}$
This model is same as model 1, while cluster effects were considered. 
$$logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}+\theta_{ij}$$
$$\theta_{ij} \sim N(0,0.4)$$

#### Missingness Model 5. x+arm+$\theta_{ij}$
This model is same as model 2, while cluster effects were considered.
$$logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}+i+\theta_{ij}$$
$$\theta_{ij} \sim N(0,0.4)$$

#### Missingness Model 6. x+arm+x:arm+$\theta_{ij}$
This model is same as model 3, while  cluster effects were considered.
$$logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}+i+X_{ijl}*i+\theta_{ij}$$
$$\theta_{ij} \sim N(0,0.4)$$

The random cluster effects added in model 4-6 is chosen as $\theta_{ij} \sim N(0,0.4)$. This can make the missing ICC as 0.1. 

The calculation methods of missing ICC is from Fan and Dr. Turner's paper $^1$ :'An evaluation of constrained randomization for the design and analysis of group-randomized trials with binary outcomes'. 

$$ \text{ICC=} \sigma_{\theta}^2/(\sigma_{\theta}^2+\pi^2/3)$$



### 4. Check the distribution of $x_{ijl}$


Check the values of $x_{ijl}$ to see whether extreme values will be generated.

#### Generate 1000,000 samples
We can firstly generate 1000,000 samples and calculate the max weigth
```{r}
try_u=rnorm(1000000,0,sqrt(3.37))
try_a=rnorm(1000,0,sqrt(0.18))
try_a2=rep(try_a,1000)
try_x=try_u+try_a2

# The max weight
1/expit(-1.34+min(try_x))
```

#### check the distriubtion of x in simulation data set:
1. Generate one data set:
```{r}
check_x1=one_group3(mis=1,s=1,i=1,k=25,mm=25,seed=123)
```

2. Check the mean value and the sd of the Xs as well as X's distribution
```{r}
mean(check_x1$x)
sd(check_x1$x)
range(check_x1$x)
hist(check_x1$x)

## max weight
1/expit(-1.34+min(check_x1$x))
```

The data generation process can gain some weights bigger than 1000, which may be relatively large. Large weights can cause nonconvergences. Then several methods are used to handle large weights. 

### 5. Weights 

To deal with large weights we can try truncation and stabilization methods.

#### Truncation method 1:
This method simply cut off all the weights that bigger than 1000. 

```{r}
mis=1
d1=data_gene3(k=25,m=25,s=1,mis=1)
d2=d1
d2$y=ifelse(d2$R==1,NA,d2$y)
d3=data.frame(y=d2$y,x=d2$x,cluster=d2$cluster,arm=d2$arm,missing=d2$R)

if(mis==1 | mis==4){
      logs=glm(missing ~ x , data = d3,
               family = binomial(link='logit'))
      logs2=glmer(missing ~ x+(1|cluster) , data = d3,
                  family = binomial(link='logit'))}
if(mis==2 | mis==5){
      logs=glm(missing ~ x+arm, data = d3,
               family = binomial(link='logit'))
      logs2=glmer(missing ~ x+arm+(1|cluster) , data = d3,
                  family = binomial(link='logit'))}
if(mis==3 | mis==6){
      logs=glm(missing ~ x+arm+x:arm, data = d3,
               family = binomial(link='logit'))
      logs2=glmer(missing ~ x+arm+x:arm+(1|cluster) , data = d3,
                  family = binomial(link='logit'))}
weight=1/expit(predict(logs))
weight2=1/expit(predict(logs2))

### cut off all the weights that bigger than 1000
d3$weight=ifelse(weight>1000,1000,weight)
d3$weight2=ifelse(weight2>1000,1000,weight2)

range(d3$weight)
range(d3$weight2)

``` 

#### Truncation method 2: 
Instead of cutting off weights bigger than a fixed value, we can set them to a less extreme value by recording all weights that are outside the 5th and 95th percentiles. 

```{r}
tsw = ifelse(weight < quantile(weight, probs=.05), quantile(weight, probs=.05), weight)
tsw = ifelse(weight > quantile(weight, probs=.95), quantile(weight, probs=.95), tsw)
        
tsw2 = ifelse(weight2 < quantile(weight2, probs=.05), 
              quantile(weight2, probs=.05), weight2)
tsw2 = ifelse(weight2 > quantile(weight2, probs=.95), 
              quantile(weight2, probs=.95), tsw2)
        
d3$weight=tsw
d3$weight2=tsw2
 
range(d3$weight)
range(d3$weight2)

```     

#### Stablization method: 
Stabilized inverse probability weights wecan be defined as$^2$: 

$$sw=\frac{f_{X}(X;\mu_1,\sigma_1^2)}{f_{X|C}(X|C=c;\mu_2,\sigma_2^2)} $$
where $f.(.)$ denotes the probability density function with mean $\mu$ and variance $\sigma^2$, and C is the set of confounders. 


```{r}

#the numerator for stablilized weights
num0 = predict(glm(missing ~ 1,data = d3,
                           family = binomial(link='logit')),type="response")

#the propensity score
ps=expit(predict(logs))
ps2=expit(predict(logs2))
        
sw=ifelse(d3$missing==1, num0/ps, (1-num0)/(1-ps))
sw2=ifelse(d3$missing==1, num0/ps2, (1-num0)/(1-ps2))
        
d3$sw=sw
d3$sw2=sw2

range(d3$sw)
range(d3$sw2)

```




# Results 

#### Data generating scenarios: S1 and S3.
S1: 

* Intervention arm and control arm: $\pi_{ijl}=exp(1+1.36 i +x_{ijl}+\delta_{ij})$

S3: 

* Intervention arm: $\pi_{ijl}=exp(1+1.36 i +x_{ijl}+\delta_{ij})$

* control arm:  $\pi_{ijl}=exp(1+1.36 i + 0.588 x_{ijl}+\delta_{ij})$

#### Missingness generation methods: mis1-mis6.

* Mis 1: $logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}$

* Mis 2: $logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}+i$

* Mis 3: $logit(R_{ijl}=0|Y_{ij},X_{ij})=-1.34 + X_{ijl}+i+X_{ijl}*i$

* Mis 4- Mis 6 are added cluster effects $\theta_{ij} \sim N(0,0.4)$  

#### Methods for dealing with extreme weights

* Truncation 1: Cut off all the weights that bigger than 1000.

* Truncation 2: Cut off all the weights that are outside the 5th and 95th percentiles

* Stabilization

By considering the scenarios mentioned above and the methods to deal with extreme weigths, we can get results shown below. 


Since we have many scenarios, the results onlys show:

* k=25, m=50 

More resutls can be found in the Excel files. 

## 1. Data generation scenario 1 with independent working correlation matrix.  

<center>**Results Table 1: with Complete Record Analysis**</center >
```{r results='asis', echo=FALSE, fig.align ='center'}

library(knitr)
library(xlsx)
library(kableExtra)


library(xlsx)
library(knitr)
setwd('c://R//ipw//data//results')
cca=c()
for(j in 1:6){
  x=read.xlsx('independent.xlsx',j)
  ccas=x[19:20,5:8]
  cca=rbind(cca,ccas)
}
cca=data.frame(cca)
rownames(cca)=NULL
tcca=t(cca)
dtcca=data.frame(tcca)
names=c('UCRA','CRA')
Methods=rep(names,6)
names(dtcca)=Methods
rownames(dtcca)=c('Est','MCSD','SD','Cov')
#cca=cbind(names,cca)
#names(cca)=c('Methods','Aveerage Estimate','MC SD','Average Estimated SD','Coverage')
cca2 <- knitr::kable(dtcca, "latex") 
add_header_above(cca2, c(" ","Mis 1" = 2, "Mis 2" = 2,"Mis 3" = 2,"Mis 4" = 2, "Mis 5" = 2,"Mis 6" = 2)) 
#cca3 <- knitr::kable(dtcca[7:12], "latex") 
#add_header_above(cca2, c(" ","Mis 4" = 2, "Mis 5" = 2,"Mis 6" = 2)) 

```
* True Effect: 1.341; 

* Missing percentage for mis1-mis6: 0.302, 0.374, 0.385, 0.309, 0.381, 0.390

* Mis: missingness generation methods. 

* UCRA: unadjusted complete record analysis. 

* CRA: adjusted complete record analysis. 

* Est: the Average estimate. 

* MCSD: Monte Carlo sd.

<center>**Results Table 2: with IPW**</center >
```{r results='asis', echo=FALSE,  fig.align ='center'}

library(knitr)
library(xlsx)
library(kableExtra)

setwd('c://R//ipw//data//results')

finals=c()
for(j in 1:6){
  x=read.xlsx('independent.xlsx',j)
  fills=matrix(0,4,15)
  for(i in 0:4){
    fills[,1+i*3]=x[c(21:24),5+i] 
    fills[,2+i*3]=x[c(26:29),5+i]
    fills[,3+i*3]=x[c(31:34),5+i]
  }
  finals=rbind(finals,fills)
}

finals=data.frame(finals)
finals2=finals[,1:12]
nn=c('M1','M2','M3')
names=rep(nn,4)
names(finals2)=names
rows=c('IPW1','IPW2','IPW1_CLU','IPW2_CLU')
Methods=c(rep(rows,6))
finals2=cbind(Methods,finals2)
xs <- knitr::kable(finals2, "latex")
# Add a row of header with 3 columns on the top of the table. The column
# span for the 2nd and 3rd one are 5 & 6.
#add_header_above(x, c(" ", "Group 1" = 5, "Group 2" = 6))
add_header_above(xs, c(" ","Estimate" = 3, "MCSD" = 3,"Estimate sd"=3,'coverage'=3)) %>%
group_rows("Missing Model 1", 1, 4) %>%
  group_rows("Missing Model 2", 5, 8) %>%
  group_rows("Missing Model 3", 9, 12) %>%
  group_rows("Missing Model 4", 13, 16) %>%
  group_rows("Missing Model 5", 17, 20) %>%
  group_rows("Missing Model 6", 21, 24) 
```

* M1: Truncation 1: Cut off all the weights that bigger than 1000. M2: Truncation 2: Cut off all the weights that are outside the 5th and 95th percentiles. M3: Stabilization.

* IPW1: ipw by using packages geepack and lme4, without cluster effects. IPW2: ipw by using package CRTgeeDR,  without cluster effects.  IPW1_CLU: ipw by using packages geepack and lme4, with cluster effects. IPW2_CLU: ipw by using package CRTgeeDR,  with cluster effects.  


## 2. Data generation scenario 1 with exchangeable working correlation matrix.

<center>**Results Table 3: with Complete Record Analysis**</center >
```{r results='asis', echo=FALSE,  fig.align='center'}

library(knitr)
library(xlsx)
library(kableExtra)


library(xlsx)
library(knitr)
setwd('c://R//ipw//data//results')
cca=c()
for(j in 1:6){
  x=read.xlsx('exchangable.xlsx',j)
  ccas=x[19:20,5:8]
  cca=rbind(cca,ccas)
}
cca=data.frame(cca)
rownames(cca)=NULL
tcca=t(cca)
dtcca=data.frame(tcca)
names=c('UCRA','CRA')
Methods=rep(names,6)
names(dtcca)=Methods
rownames(dtcca)=c('Est','MCSD','SD','Cov')
#cca=cbind(names,cca)
#names(cca)=c('Methods','Aveerage Estimate','MC SD','Average Estimated SD','Coverage')
cca2 <- knitr::kable(dtcca, "latex") 
add_header_above(cca2, c(" ","Mis 1" = 2, "Mis 2" = 2,"Mis 3" = 2,"Mis 4" = 2, "Mis 5" = 2,"Mis 6" = 2)) 
#cca3 <- knitr::kable(dtcca[7:12], "latex") 
#add_header_above(cca2, c(" ","Mis 4" = 2, "Mis 5" = 2,"Mis 6" = 2)) 

```
* True Effect: 1.338; 

* Missing percentage for mis1-mis6: 0.302, 0.374, 0.385, 0.309, 0.381, 0.390

* Mis: missingness generation methods. UCRA: unadjusted complete record analysis. CRA: adjusted complete record analysis. Est:  the Average estimate. MCSD: Monte Carlo sd. Cov: coverage ($\%$).

<center>**Results Table 4: with IPW**</center >
```{r results='asis', echo=FALSE, fig.align ='center'}

library(knitr)
library(xlsx)
library(kableExtra)

setwd('c://R//ipw//data//results')

finals=c()
for(j in 1:6){
  x=read.xlsx('exchangable.xlsx',j)
  fills=matrix(0,4,15)
  for(i in 0:4){
    fills[,1+i*3]=x[c(21:24),5+i] 
    fills[,2+i*3]=x[c(26:29),5+i]
    fills[,3+i*3]=x[c(31:34),5+i]
  }
  finals=rbind(finals,fills)
}

finals=data.frame(finals)
finals2=finals[,1:12]
nn=c('M1','M2','M3')
names=rep(nn,4)
names(finals2)=names
rows=c('IPW1','IPW2','IPW1_CLU','IPW2_CLU')
Methods=c(rep(rows,6))
finals2=cbind(Methods,finals2)
xs <- knitr::kable(finals2, "latex")
# Add a row of header with 3 columns on the top of the table. The column
# span for the 2nd and 3rd one are 5 & 6.
#add_header_above(x, c(" ", "Group 1" = 5, "Group 2" = 6))
add_header_above(xs, c(" ","Estimate" = 3, "MCSD" = 3,"Estimate sd"=3,'coverage'=3)) %>%
group_rows("Missing Model 1", 1, 4) %>%
  group_rows("Missing Model 2", 5, 8) %>%
  group_rows("Missing Model 3", 9, 12) %>%
  group_rows("Missing Model 4", 13, 16) %>%
  group_rows("Missing Model 5", 17, 20) %>%
  group_rows("Missing Model 6", 21, 24) 
```

* M1: Truncation 1: Cut off all the weights that bigger than 1000. M2: Truncation 2: Cut off all the weights that are outside the 5th and 95th percentiles. M3: Stabilization.

* IPW1: ipw by using packages geepack and lme4, without cluster effects. IPW2: ipw by using package CRTgeeDR,  without cluster effects.  IPW1_CLU: ipw by using packages geepack and lme4, with cluster effects. IPW2_CLU: ipw by using package CRTgeeDR,  with cluster effects.  

## 3. Data generation scenario 2 with independent working correlation matrix.

<center>**Results Table 5: with Complete Record Analysis**</center >
```{r results='asis', echo=FALSE, fig.align ='center'}

library(knitr)
library(xlsx)
library(kableExtra)


library(xlsx)
library(knitr)
setwd('c://R//ipw//data//results')
cca=c()
for(j in 1:6){
  x=read.xlsx('ind2.xlsx',j)
  ccas=x[19:20,5:8]
  cca=rbind(cca,ccas)
}
cca=data.frame(cca)
rownames(cca)=NULL
tcca=t(cca)
dtcca=data.frame(tcca)
names=c('UCRA','CRA')
Methods=rep(names,6)
names(dtcca)=Methods
rownames(dtcca)=c('Est','MCSD','SD','Cov')
#cca=cbind(names,cca)
#names(cca)=c('Methods','Aveerage Estimate','MC SD','Average Estimated SD','Coverage')
cca2 <- knitr::kable(dtcca, "latex") 
add_header_above(cca2, c(" ","Mis 1" = 2, "Mis 2" = 2,"Mis 3" = 2,"Mis 4" = 2, "Mis 5" = 2,"Mis 6" = 2)) 
#cca3 <- knitr::kable(dtcca[7:12], "latex") 
#add_header_above(cca2, c(" ","Mis 4" = 2, "Mis 5" = 2,"Mis 6" = 2)) 

```

* True Effect: 1.341; 

* Missing percentage for mis1-mis6: 0.302, 0.374, 0.385, 0.309, 0.381, 0.390

* Mis: missingness generation methods. UCRA: unadjusted complete record analysis. CRA: adjusted complete record analysis. Est:  the Average estimate. MCSD: Monte Carlo sd. Cov: coverage ($\%$).

<center>**Results Table 6: with IPW**</center >
```{r results='asis', echo=FALSE,  fig.align ='center'}

library(knitr)
library(xlsx)
library(kableExtra)

setwd('c://R//ipw//data//results')

finals=c()
for(j in 1:6){
  x=read.xlsx('ind2.xlsx',j)
  fills=matrix(0,4,15)
  for(i in 0:4){
    fills[,1+i*3]=x[c(21:24),5+i] 
    fills[,2+i*3]=x[c(26:29),5+i]
    fills[,3+i*3]=x[c(31:34),5+i]
  }
  finals=rbind(finals,fills)
}

finals=data.frame(finals)
finals2=finals[,1:12]
nn=c('M1','M2','M3')
names=rep(nn,4)
names(finals2)=names
rows=c('IPW1','IPW2','IPW1_CLU','IPW2_CLU')
Methods=c(rep(rows,6))
finals2=cbind(Methods,finals2)
xs <- knitr::kable(finals2, "latex")
# Add a row of header with 3 columns on the top of the table. The column
# span for the 2nd and 3rd one are 5 & 6.
#add_header_above(x, c(" ", "Group 1" = 5, "Group 2" = 6))
add_header_above(xs, c(" ","Estimate" = 3, "MCSD" = 3,"Estimate sd"=3,'coverage'=3)) %>%
group_rows("Missing Model 1", 1, 4) %>%
  group_rows("Missing Model 2", 5, 8) %>%
  group_rows("Missing Model 3", 9, 12) %>%
  group_rows("Missing Model 4", 13, 16) %>%
  group_rows("Missing Model 5", 17, 20) %>%
  group_rows("Missing Model 6", 21, 24) 
```

* M1: Truncation 1: Cut off all the weights that bigger than 1000. M2: Truncation 2: Cut off all the weights that are outside the 5th and 95th percentiles. M3: Stabilization.

* IPW1: ipw by using packages geepack and lme4, without cluster effects. IPW2: ipw by using package CRTgeeDR,  without cluster effects.  IPW1_CLU: ipw by using packages geepack and lme4, with cluster effects. IPW2_CLU: ipw by using package CRTgeeDR,  with cluster effects.  

## 4. Data generation scenario 2 with exchangeable working correlation matrix.

<center>**Results Table 7: with Complete Record Analysis**</center >
```{r echo=FALSE,  fig.align ='center'}

library(knitr)
library(xlsx)
library(kableExtra)


library(xlsx)
library(knitr)
setwd('c://R//ipw//data//results')
cca=c()
for(j in 1:6){
  x=read.xlsx('ex2.xlsx',j)
  ccas=x[19:20,5:8]
  cca=rbind(cca,ccas)
}
cca=data.frame(cca)
rownames(cca)=NULL
tcca=t(cca)
dtcca=data.frame(tcca)
names=c('UCRA','CRA')
Methods=rep(names,6)
names(dtcca)=Methods
rownames(dtcca)=c('Est','MCSD','SD','Cov')
#cca=cbind(names,cca)
#names(cca)=c('Methods','Aveerage Estimate','MC SD','Average Estimated SD','Coverage')
cca2 <- knitr::kable(dtcca, "latex") 
add_header_above(cca2, c(" ","Mis 1" = 2, "Mis 2" = 2,"Mis 3" = 2,"Mis 4" = 2, "Mis 5" = 2,"Mis 6" = 2)) 
#cca3 <- knitr::kable(dtcca[7:12], "latex") 
#add_header_above(cca2, c(" ","Mis 4" = 2, "Mis 5" = 2,"Mis 6" = 2)) 

```

* True Effect: 1.341;

* Missing percentage for mis1-mis6: 0.302, 0.374, 0.385, 0.309, 0.381, 0.390

* Mis: missingness generation methods. UCRA: unadjusted complete record analysis. CRA: adjusted complete record analysis. Est: the Average estimate. MCSD: Monte Carlo sd. Cov: converage ($\%$).

<center>**Results Table 8 with IPW**</center >
```{r results='asis', echo=FALSE,  fig.align ='center'}

library(knitr)
library(xlsx)
library(kableExtra)

setwd('c://R//ipw//data//results')

finals=c()
for(j in 1:6){
  x=read.xlsx('ex2.xlsx',j)
  fills=matrix(0,4,15)
  for(i in 0:4){
    fills[,1+i*3]=x[c(21:24),5+i] 
    fills[,2+i*3]=x[c(26:29),5+i]
    fills[,3+i*3]=x[c(31:34),5+i]
  }
  finals=rbind(finals,fills)
}

finals=data.frame(finals)
finals2=finals[,1:12]
nn=c('M1','M2','M3')
names=rep(nn,4)
names(finals2)=names
rows=c('IPW1','IPW2','IPW1_CLU','IPW2_CLU')
Methods=c(rep(rows,6))
finals2=cbind(Methods,finals2)
xs <- knitr::kable(finals2, "latex")
# Add a row of header with 3 columns on the top of the table. The column
# span for the 2nd and 3rd one are 5 & 6.
#add_header_above(x, c(" ", "Group 1" = 5, "Group 2" = 6))
add_header_above(xs, c(" ","Estimate" = 3, "MCSD" = 3,"Estimate sd"=3,'coverage'=3)) %>%
group_rows("Missing Model 1", 1, 4) %>%
  group_rows("Missing Model 2", 5, 8) %>%
  group_rows("Missing Model 3", 9, 12) %>%
  group_rows("Missing Model 4", 13, 16) %>%
  group_rows("Missing Model 5", 17, 20) %>%
  group_rows("Missing Model 6", 21, 24) 
```

* M1: Truncation 1: Cut off all the weights that bigger than 1000. M2: Truncation 2: Cut off all the weights that are outside the 5th and 95th percentiles. M3: Stabilization.

* IPW1: ipw by using packages geepack and lme4, without cluster effects. IPW2: ipw by using package CRTgeeDR,  without cluster effects.  IPW1_CLU: ipw by using packages geepack and lme4, with cluster effects. IPW2_CLU: ipw by using package CRTgeeDR,  with cluster effects.  


<center>**Non convergence times**</center >

```{r results='asis', echo=FALSE}

library(knitr)
library(xlsx)
library(kableExtra)


library(xlsx)
library(knitr)

setwd('c:\\Users\\apple\\Documents')

ex1=read.csv('datas3m1_ex30.05.csv')
ex1=ex1[ex1$k==3,]
ex3=read.csv('datas3m3_ex30.05.csv')
ex3=ex3[ex3$k==3,]

rownames(ex1)=NULL
rownames(ex3)=NULL
ex1=ex1[,c('X','unc_time')]
ex3=ex3[,c('X','unc_time')]

m1=c()
m2=c()
m3=c()

for(i in 1:6){
  m1=rbind(m1,ex1[(3+(i-1)*6):(6+(i-1)*6),]) 
  m2=rbind(m2,ex3[(3+(i-1)*10):(6+(i-1)*10),])
  m3=rbind(m3,ex3[(7+(i-1)*10):(10+(i-1)*10),])
}

nam=c('IPW1','IPW2','IPW1_CLU','IPW2_CLU')
m1$X=rep(nam,6)
m2$X=rep(nam,6)
m3$X=rep(nam,6)

ind1=read.csv('datas3m1ind30.05.csv')
ind1=ind1[ind1$k==3,]
ind3=read.csv('datas3m3ind30.05.csv')
ind3=ind3[ind3$k==3,]

rownames(ind1)=NULL
rownames(ind3)=NULL
ind1=ind1[,c('X','unc_time')]
ind3=ind3[,c('X','unc_time')]

M1=c()
M2=c()
M3=c()

for(i in 1:6){
  M1=rbind(M1,ind1[c((3+(i-1)*7):(4+(i-1)*7),(6+(i-1)*7):(7+(i-1)*7)),]) 
  M2=rbind(M2,ind3[(3+(i-1)*10):(6+(i-1)*10),])
  M3=rbind(M3,ind3[(7+(i-1)*10):(10+(i-1)*10),])
}

nam=c('IPW1','IPW2','IPW1_CLU','IPW2_CLU')
M1$X=rep(nam,6)
M2$X=rep(nam,6)
M3$X=rep(nam,6)

rownames(M1)=NULL
rownames(M2)=NULL

unc=cbind(M1,M2,M3,m1,m2,m3)
unc=unc[,c(1,2,seq(4,12,2))]

names(unc)=c('Methods','M1','M2','M3','M1','M2','M3')
rownames(unc)=NULL

xs <- knitr::kable(unc, "latex")
# Add a row of header with 3 columns on the top of the table. The column
# span for the 2nd and 3rd one are 5 & 6.
#add_header_above(x, c(" ", "Group 1" = 5, "Group 2" = 6))
add_header_above(xs, c(" ","Independent" = 3, "Exchangeable" = 3)) %>%
group_rows("Missing Model 1", 1, 4) %>%
  group_rows("Missing Model 2", 5, 8) %>%
  group_rows("Missing Model 3", 9, 12) %>%
  group_rows("Missing Model 4", 13, 16) %>%
  group_rows("Missing Model 5", 17, 20) %>%
  group_rows("Missing Model 6", 21, 24) 

```

* M1: Truncation 1: Cut off all the weights that bigger than 1000. M2: Truncation 2: Cut off all the weights that are outside the 5th and 95th percentiles. M3: Stabilization.

* IPW1: ipw by using packages geepack and lme4, without cluster effects. IPW2: ipw by using package CRTgeeDR,  without cluster effects.  IPW1_CLU: ipw by using packages geepack and lme4, with cluster effects. IPW2_CLU: ipw by using package CRTgeeDR,  with cluster effects.  


By dealing with weights of IPW, we still gain some nonconvergence times. The truncation method 1 gets more non-convergences since it still contains relatively large weight 1000. The truncation method 2 and stabilization method get weights that are smaller than 100, which reduce the number of non-convergence a lot. 

## Multiple Imputation

To compare with IPW, multilevel multiple imputation and standard MI are performed with independent and exchangeable working correlation matrix GEE. 

The result only shows: 

* data generation scenario 1

* scenario: k=25, m=50

```{r results='asis', include=FALSE}
library(knitr)
library(xlsx)
library(kableExtra)


library(xlsx)
library(knitr)

setwd('c://R//ipw//data//results')

data=read.csv('data_mmi.csv')
mmi=data[data$k==3,]

names=c('MMI_ind','Standard MI_ind','MMI_exch','Standard MI_exch')
names=data.frame(rep(names,6))
numbers=round(mmi[,2:5],3)
data2=cbind(mmi$mis,names,numbers)
names(data2)=c('Missing model','Methods','Average Estimate',
               'MC-SD','Average Estimate SD','Coverage (%)')
kable(data2)
```


| Missing model|Methods          | Average Estimate| MC-SD| Average Estimate SD| Coverage (%)|
|:-------------|:----------------|----------------:|-----:|-------------------:|------------:|
|             1|MMI_ind          |            1.126| 0.109|               0.175|           75|
|             |Standard MI_ind  |            1.126| 0.109|               0.178|           77|
|             |MMI_exch         |            1.126| 0.110|               0.178|           77|
|             |Standard MI_exch |            1.361| 0.110|               0.171|           98|
|             2|MMI_ind          |            1.364| 0.142|               0.189|          100|
|             |Standard MI_ind  |            1.367| 0.142|               0.193|           99|
|             |MMI_exch         |            1.367| 0.141|               0.193|           99|
|             |Standard MI_exch |            1.369| 0.141|               0.193|           97|
|             3|MMI_ind          |            1.361| 0.144|               0.196|          100|
|             |Standard MI_ind  |            1.364| 0.144|               0.197|           98|
|             |MMI_exch         |            1.364| 0.144|               0.197|           98|
|             |Standard MI_exch |            1.371| 0.144|               0.185|           97|
|             4|MMI_ind          |            1.345| 0.134|               0.173|           98|
|             |Standard MI_ind  |            1.346| 0.134|               0.173|           97|
|             |MMI_exch         |            1.346| 0.135|               0.173|           97|
|             |Standard MI_exch |            1.353| 0.135|               0.174|           99|
|             5|MMI_ind          |            1.324| 0.145|               0.195|          100|
|             |Standard MI_ind  |            1.326| 0.145|               0.195|           97|
|             |MMI_exch         |            1.326| 0.146|               0.195|           97|
|             |Standard MI_exch |            1.351| 0.146|               0.191|           97|
|             6|MMI_ind          |            1.328| 0.152|               0.202|           98|
|             |Standard MI_ind  |            1.329| 0.152|               0.205|           97|
|             |MMI_exch         |            1.329| 0.154|               0.205|           97|
|             |Standard MI_exch |            1.369| 0.154|               0.188|           96|

* MMI_ind: multiple MI with independent working correlation matrix

* Standard MI_ind: standard MI with independent working correlation matrix

* MMI_exch: multiple MI with exchangeable  working correlation matrix

* Standard MI_exch: standard MI with  exchangeable working correlation matrix

#### For estimates: 

Adjusted CRA, IPW and MMI generate results that are similar with true effects with each scenario. I think they can be considered as unbiased estimates. 

The IPW method 1 and IPW method 2 can gain close results, especially under exchangeable working correlation matrixes.The truncation 2 and stabilization weighting methods tend to get better results than cutting of weights bigger than 1000. The results from these 4 IPW methods are quite similar to each other when using stabilization methods to deal with weights.  

With independent working correlation matrixes, the differences between standard MI and MMI in each scenario are quite small, while with exchangeable ones, they are different and MMI are closer to true effects. MMI seems work better when meeting scenarios with interactions. MI methods with missing model 1 gain weird results, I will double check my code. 

The Monte Carlo SDs and average estimate SDs are within acceptable ranges.  

#### For coverage rate:

In general, IPW performs better with simple scenarios (e.g, mis 1, mis 2, mis 4, mis 5) and data generation scenario 1, which does not have interaction with intervention arm and covariate X. Also, the results are better with independent working correlation matrixes then exchangeable ones.With exchangeable working correlation matrixes, IPW tends to be over-coverage.

Adjusted CRA tends to be over-coverage.

MI methods also tend to be over-coverage, especially with an independent working correlation matrix. 


### Reference

[1] Li F, Turner E L, Heagerty P J, et al. An evaluation of constrained randomization for the design and analysis of group-randomized trials with binary outcomes[J]. Statistics in Medicine, 2017, 35(10):1565-1579.

[2] Sato T, Matsuyama Y. Marginal structural models as a tool for standardization.Epidemiology. 2003;14:680¨C686.

